{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eduahoge\\AppData\\Local\\miniconda3\\envs\\llava\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\eduahoge\\AppData\\Local\\miniconda3\\envs\\llava\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\eduahoge\\AppData\\Local\\miniconda3\\envs\\llava\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running combination: RN50, first extraction, top_k = 1 ===\n",
      "\n",
      "Loading CLIP model RN50 on cuda ...\n",
      "Loading cached training embeddings from training_embeddings_RN50_first.pt ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing validation videos [RN50, first, top_k=1]:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('LLaVA')\n",
    "sys.path.append('C:\\\\transf\\\\XAI_DEEPFAKE\\\\LLaVA')\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from pathlib import Path\n",
    "import json\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import get_model_name_from_path\n",
    "from llava.eval.run_llava import eval_model_frame\n",
    "from tqdm import tqdm\n",
    "import clip\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class MaskUtils:\n",
    "    @staticmethod\n",
    "    def apply_mask(frame, keypoint, use_hard_mask=True, radius=75):\n",
    "        h, w, c = frame.shape\n",
    "        kp_x = keypoint[\"x\"] * w\n",
    "        kp_y = keypoint[\"y\"] * h\n",
    "        yy, xx = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')\n",
    "        distance = np.sqrt((xx - kp_x)*2 + (yy - kp_y)*2)\n",
    "        mask = (distance <= radius).astype(np.uint8)\n",
    "        if use_hard_mask:\n",
    "            for ch in range(c):\n",
    "                frame[:, :, ch] = frame[:, :, ch] * mask\n",
    "        else:\n",
    "            blur_ksize = 83\n",
    "            dilation_iter = 1\n",
    "            mask = mask.astype(np.float32)\n",
    "            blurred = cv2.GaussianBlur(mask, (blur_ksize, blur_ksize), 83)\n",
    "            blurred_normalized = cv2.normalize(blurred, None, 0, 1, cv2.NORM_MINMAX)\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "            dilated = cv2.dilate(blurred_normalized, kernel, iterations=dilation_iter)\n",
    "            for ch in range(c):\n",
    "                frame[:, :, ch] = frame[:, :, ch].astype(np.float32) * dilated\n",
    "            frame = frame.astype(np.uint8)\n",
    "        return frame\n",
    "\n",
    "\n",
    "def safe_load_model(model_path, max_retries=3, delay=5):\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            tokenizer, llava_model, image_processor, context_len = load_pretrained_model(\n",
    "                model_path=model_path,\n",
    "                model_base=None,\n",
    "                model_name=get_model_name_from_path(model_path)\n",
    "            )\n",
    "            return tokenizer, llava_model, image_processor, context_len\n",
    "        except ZeroDivisionError:\n",
    "            print(f\"ZeroDivisionError during model loading. Retrying... (Attempt {attempt + 1})\")\n",
    "            time.sleep(delay)\n",
    "            attempt += 1\n",
    "    raise RuntimeError(\"Failed to load the model after multiple attempts\")\n",
    "\n",
    "# -------------------------------\n",
    "# CLIP embedding extraction\n",
    "# -------------------------------\n",
    "def get_clip_embedding(image, layer=\"last\"):\n",
    "    # Use the global clip_model and preprocess (set per combination)\n",
    "    image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "    image_tensor = image_tensor.half() if clip_model.visual.conv1.weight.dtype == torch.half else image_tensor\n",
    "    with torch.no_grad():\n",
    "        if layer == \"first\":\n",
    "            x = clip_model.visual.conv1(image_tensor)\n",
    "            x = clip_model.visual.bn1(x)\n",
    "            x = clip_model.visual.relu1(x)\n",
    "            x = clip_model.visual.conv2(x)\n",
    "            x = clip_model.visual.bn2(x)\n",
    "            x = clip_model.visual.relu2(x)\n",
    "            x = clip_model.visual.conv3(x)\n",
    "            x = clip_model.visual.bn3(x)\n",
    "            x = clip_model.visual.relu3(x)\n",
    "            x = clip_model.visual.avgpool(x)\n",
    "            embedding = x\n",
    "        elif layer == \"middle\":\n",
    "            x = clip_model.visual.conv1(image_tensor)\n",
    "            x = clip_model.visual.bn1(x)\n",
    "            x = clip_model.visual.relu1(x)\n",
    "            x = clip_model.visual.conv2(x)\n",
    "            x = clip_model.visual.bn2(x)\n",
    "            x = clip_model.visual.relu2(x)\n",
    "            x = clip_model.visual.conv3(x)\n",
    "            x = clip_model.visual.bn3(x)\n",
    "            x = clip_model.visual.relu3(x)\n",
    "            x = clip_model.visual.avgpool(x)\n",
    "            x = clip_model.visual.layer1(x)\n",
    "            x = clip_model.visual.layer2(x)\n",
    "            x = clip_model.visual.layer3(x)\n",
    "            embedding = x\n",
    "        elif layer == \"last\":\n",
    "            embedding = clip_model.encode_image(image_tensor)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid layer specified. Choose from 'first', 'middle', or 'last'.\")\n",
    "        embedding = embedding.view(embedding.size(0), -1)  # flatten spatial dimensions\n",
    "    return embedding\n",
    "\n",
    "# -------------------------------\n",
    "# Prompt creation\n",
    "# -------------------------------\n",
    "def create_custom_prompt(annotations, prompt_version=1):\n",
    "    if prompt_version == 1:\n",
    "        base_prompt = (\n",
    "            \"Based on the following descriptions: {annotations}, analyze the face in the image and \"\n",
    "            \"identify any signs of deepfake artifacts. Consider how the descriptions might relate to \"\n",
    "            \"potential manipulations. Look for abnormalities such as inconsistent lighting, unnatural \"\n",
    "            \"facial movements, blurriness around the edges, strange reflections in the eyes, mismatched \"\n",
    "            \"facial features, or any other indications of digital manipulation. Provide a detailed \"\n",
    "            \"description of any anomalies found.\"\n",
    "        )\n",
    "    if prompt_version == 2:\n",
    "        base_prompt = (\n",
    "            \"Analyze the face in the image based on the description: '{annotations}'. Identify any \"\n",
    "            \"deepfake artifacts, focusing specifically on the affected parts of the face mentioned. \"\n",
    "            \"Provide a short and direct explanation highlighting the inconsistencies or manipulations.\"\n",
    "        )\n",
    "    if prompt_version == 3:\n",
    "        base_prompt = (\n",
    "            \"Based on the following annotations: {annotations}, examine the face in the image for any signs of deepfake manipulation. \"\n",
    "            \"Note that the annotations highlight possible alterations, but there may be additional anomalies not captured by them. \"\n",
    "            \"Provide a concise and objective analysis identifying any inconsistencies, artifacts, or unusual features that could indicate digital manipulation.\"\n",
    "            )\n",
    "\n",
    "    return base_prompt.format(annotations=', '.join(f'\"{ann}\"' for ann in annotations))\n",
    "\n",
    "# -------------------------------\n",
    "# Deepfake detection using LLaVA\n",
    "# -------------------------------\n",
    "def detect_deepfake(frame, custom_prompt):\n",
    "    if isinstance(frame, np.ndarray):\n",
    "        frame = frame.astype('uint8')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid frame data. Expected a NumPy array.\")\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image_pil = Image.fromarray(frame_rgb)\n",
    "    local_args = type('Args', (), {\n",
    "        \"model_path\": model_path,\n",
    "        \"model_base\": None,\n",
    "        \"model_name\": get_model_name_from_path(model_path),\n",
    "        \"query\": custom_prompt,\n",
    "        \"conv_mode\": None,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": None,\n",
    "        \"num_beams\": 1,\n",
    "        \"max_new_tokens\": 512,\n",
    "    })()\n",
    "    predicted_sentence = eval_model_frame(\n",
    "        local_args,\n",
    "        image_pil,\n",
    "        tokenizer=tokenizer,\n",
    "        model=llava_model,\n",
    "        image_processor=image_processor\n",
    "    )\n",
    "    return predicted_sentence\n",
    "\n",
    "# -------------------------------\n",
    "# Data grouping\n",
    "# -------------------------------\n",
    "def get_training_frames(df):\n",
    "    training_frames = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        video_name = row['movie_name']\n",
    "        manipulation_path = Path('C:/transf/XAI_DEEPFAKE/LLaVA') / row['manipulation']\n",
    "        video_path = (manipulation_path / video_name).resolve()\n",
    "        click_locations = row['click_locations']\n",
    "        if not click_locations or pd.isna(click_locations):\n",
    "            continue\n",
    "        try:\n",
    "            frame_data = json.loads(click_locations)\n",
    "            for frame_str, _ in frame_data.items():\n",
    "                if frame_str.isdigit():\n",
    "                    frame_num = int(frame_str) - 1\n",
    "                    if video_path not in training_frames:\n",
    "                        training_frames[video_path] = []\n",
    "                    training_frames[video_path].append((frame_num, row['text']))\n",
    "        except:\n",
    "            continue\n",
    "    for video_path, frames in training_frames.items():\n",
    "        training_frames[video_path] = sorted(frames, key=lambda x: x[0])\n",
    "    return training_frames\n",
    "\n",
    "def get_validation_frames(df, num_files=0):\n",
    "    frames_dict = {}\n",
    "    total_rows = len(df)\n",
    "    if num_files > 0:\n",
    "        total_rows = min(total_rows, num_files)\n",
    "    for idx, row in df.iterrows():\n",
    "        if num_files > 0 and idx >= num_files:\n",
    "            break\n",
    "        video_name = row['movie_name']\n",
    "        manipulation_path = Path('C:/transf/XAI_DEEPFAKE/LLaVA') / row['manipulation']\n",
    "        video_path = (manipulation_path / video_name).resolve()\n",
    "        click_locations = row['click_locations']\n",
    "        if not click_locations or pd.isna(click_locations):\n",
    "            continue\n",
    "        try:\n",
    "            frame_data = json.loads(click_locations)\n",
    "            if video_path not in frames_dict:\n",
    "                frames_dict[video_path] = {}\n",
    "            for frame_str, kpt_info in frame_data.items():\n",
    "                if frame_str.isdigit():\n",
    "                    frame_num = int(frame_str) - 1\n",
    "                    if frame_num not in frames_dict[video_path]:\n",
    "                        frames_dict[video_path][frame_num] = []\n",
    "                    if isinstance(kpt_info, dict):\n",
    "                        frames_dict[video_path][frame_num].append(kpt_info)\n",
    "                    elif isinstance(kpt_info, list):\n",
    "                        frames_dict[video_path][frame_num].extend(kpt_info)\n",
    "        except:\n",
    "            continue\n",
    "    final_frames = {}\n",
    "    for video_path, frame_map in frames_dict.items():\n",
    "        final_frames[video_path] = sorted(\n",
    "            [(fnum, kpts) for fnum, kpts in frame_map.items()],\n",
    "            key=lambda x: x[0]\n",
    "        )\n",
    "    return final_frames\n",
    "\n",
    "# -------------------------------\n",
    "# Main pipeline\n",
    "# -------------------------------\n",
    "def run_pipeline(rn_model_name, extraction_layer, top_k, num_files=0, mask_on=False, use_hard_mask=True, prompt_version=1):\n",
    "    global clip_model, preprocess  # update global clip model variables\n",
    "    # Load the specified CLIP model\n",
    "    print(f\"\\nLoading CLIP model {rn_model_name} on {device} ...\")\n",
    "    clip_model, preprocess = clip.load(rn_model_name, device=device)\n",
    "    clip_model.eval()\n",
    "\n",
    "    # Group frames for training and validation\n",
    "    train_frames = get_training_frames(train_df)\n",
    "    val_frames = get_validation_frames(val_df, num_files)\n",
    "\n",
    "    emb_save_path = f\"training_embeddings_{rn_model_name}_{extraction_layer}.pt\"\n",
    "    if os.path.exists(emb_save_path):\n",
    "        print(f\"Loading cached training embeddings from {emb_save_path} ...\")\n",
    "        emb_data = torch.load(emb_save_path)\n",
    "        training_embeddings_tensor = emb_data['embeddings']\n",
    "        training_annotations = emb_data['annotations']\n",
    "        training_keys = emb_data['keys']\n",
    "    else:\n",
    "        print(f\"Computing training embeddings for [{rn_model_name}, {extraction_layer}] ...\")\n",
    "        training_embeddings_list = []\n",
    "        training_annotations = []\n",
    "        training_keys = []  # (video_path, frame_number)\n",
    "        for video_path, frames in tqdm(train_frames.items(), desc=f\"Processing training videos [{rn_model_name}, {extraction_layer}]\"):\n",
    "            cap = cv2.VideoCapture(str(video_path))\n",
    "            if not cap.isOpened():\n",
    "                continue\n",
    "            for (frame_number, annotation) in frames:\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    continue\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image_pil = Image.fromarray(frame_rgb)\n",
    "                embedding = get_clip_embedding(image_pil, layer=extraction_layer)\n",
    "                training_embeddings_list.append(embedding)\n",
    "                training_annotations.append(annotation)\n",
    "                training_keys.append((video_path, frame_number))\n",
    "            cap.release()\n",
    "        if len(training_embeddings_list) == 0:\n",
    "            raise RuntimeError(\"No training embeddings computed.\")\n",
    "        training_embeddings_tensor = torch.cat(training_embeddings_list, dim=0)\n",
    "        torch.save({\n",
    "            'embeddings': training_embeddings_tensor,\n",
    "            'annotations': training_annotations,\n",
    "            'keys': training_keys\n",
    "        }, emb_save_path)\n",
    "        print(f\"Saved training embeddings to {emb_save_path}\")\n",
    "\n",
    "    # Process validation videos and run LLaVA for predictions\n",
    "    results = []\n",
    "    for video_path, frame_info_list in tqdm(val_frames.items(), desc=f\"Analyzing validation videos [{rn_model_name}, {extraction_layer}, top_k={top_k}]\"):\n",
    "        cap = cv2.VideoCapture(str(video_path))\n",
    "        if not cap.isOpened():\n",
    "            continue\n",
    "        for (frame_number, keypoints) in frame_info_list:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image_pil = Image.fromarray(frame_rgb)\n",
    "            val_embedding = get_clip_embedding(image_pil, layer=extraction_layer)\n",
    "            sims = cosine_similarity(val_embedding, training_embeddings_tensor)\n",
    "            topk_values, topk_indices = torch.topk(sims, k=top_k)\n",
    "            topk_annotations = [training_annotations[i] for i in topk_indices.tolist()]\n",
    "            custom_prompt = create_custom_prompt(topk_annotations, prompt_version=prompt_version) if topk_annotations else \"No annotation available\"\n",
    "\n",
    "            # Optional masking\n",
    "            frame_for_llava = frame.copy()\n",
    "            if mask_on and keypoints:\n",
    "                for kp in keypoints:\n",
    "                    frame_for_llava = MaskUtils.apply_mask(frame_for_llava, kp, use_hard_mask=use_hard_mask, radius=75)\n",
    "\n",
    "            test_deepfake_analysis = detect_deepfake(frame_for_llava, custom_prompt) if topk_annotations else \"No analysis available\"\n",
    "            \n",
    "            results.append({\n",
    "                'rn_model': rn_model_name,\n",
    "                'extraction_layer': extraction_layer,\n",
    "                'top_k': top_k,\n",
    "                'validation_video': str(video_path),\n",
    "                'validation_frame': frame_number,\n",
    "                'closest_train_annotations': topk_annotations,\n",
    "                'test_deepfake_analysis': test_deepfake_analysis,\n",
    "                'top_k_similarities': topk_values.tolist(),\n",
    "                'prompt_version_used': prompt_version,\n",
    "            })\n",
    "        cap.release()\n",
    "    return results\n",
    "\n",
    "# -------------------------------\n",
    "# Main loop over combinations and top-k values\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = \"liuhaotian/llava-v1.5-7b\"\n",
    "    tokenizer, llava_model, image_processor, context_len = safe_load_model(model_path)\n",
    "    llava_model = llava_model.to(device)\n",
    "    \n",
    "    # Load dataset and split into training and validation sets\n",
    "    csv_path = r'C:\\transf\\XAI_DEEPFAKE\\dataset.csv'\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "    video_paths = df['movie_name'].unique()\n",
    "    val_videos = video_paths[:100]\n",
    "    train_videos = video_paths[100:]\n",
    "    global train_df, val_df\n",
    "    train_df = df[df['movie_name'].isin(train_videos)]\n",
    "    val_df = df[df['movie_name'].isin(val_videos)]\n",
    "    \n",
    "    # List of RN models, extraction layers, and top-k values\n",
    "    rn_models = [\"RN50\", \"RN101\"]\n",
    "    extraction_layers = [\"first\", \"middle\", \"last\"]\n",
    "    top_k_values = [1, 3, 5, 10]\n",
    "    \n",
    "    all_results = []\n",
    "    for rn_model_name in rn_models:\n",
    "        for extraction_layer in extraction_layers:\n",
    "            for top_k in top_k_values:\n",
    "                print(f\"\\n=== Running combination: {rn_model_name}, {extraction_layer} extraction, top_k = {top_k} ===\")\n",
    "                comb_results = run_pipeline(\n",
    "                    rn_model_name=rn_model_name,\n",
    "                    extraction_layer=extraction_layer,\n",
    "                    top_k=top_k,\n",
    "                    num_files=10,         # set >0 to limit rows processed, 0 for all data\n",
    "                    mask_on=True,\n",
    "                    use_hard_mask=True,\n",
    "                    prompt_version=3\n",
    "                )\n",
    "                comb_csv_path = f\"results_{rn_model_name}_{extraction_layer}_k{top_k}.csv\"\n",
    "                pd.DataFrame(comb_results).to_csv(comb_csv_path, index=False)\n",
    "                print(f\"Saved results to {comb_csv_path}\")\n",
    "                all_results.extend(comb_results)\n",
    "    \n",
    "    combined_csv_path = \"results_all_combinations.csv\"\n",
    "    pd.DataFrame(all_results).to_csv(combined_csv_path, index=False)\n",
    "    print(f\"\\nAll results saved to {combined_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset with GT column saved to results_all_combinations_merged.csv\n",
      "Loading BERT and Sentence-BERT models ...\n",
      "Overall Average Cosine Similarity (BERT): 0.5216581641385952\n",
      "Overall Average Cosine Similarity (Sentence-BERT): 0.04524932078654981\n",
      "Evaluation results saved to results_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# -------------------------------\n",
    "#  paths\n",
    "# -------------------------------\n",
    "dataset_path = r'C:\\transf\\XAI_DEEPFAKE\\dataset.csv'\n",
    "combined_results_path = r'results_all_combinations.csv'\n",
    "merged_output_path = r'results_all_combinations_merged.csv'\n",
    "evaluation_output_path = r'results_evaluation.csv'\n",
    "\n",
    "# -------------------------------\n",
    "# Load dataset and combined results\n",
    "# -------------------------------\n",
    "df_dataset = pd.read_csv(dataset_path)\n",
    "df_results = pd.read_csv(combined_results_path)\n",
    "\n",
    "df_dataset = df_dataset[['movie_name', 'text']]\n",
    "unique_video_annotations = df_dataset.drop_duplicates(subset='movie_name')\n",
    "\n",
    "df_results['movie_name'] = df_results['validation_video'].apply(lambda x: os.path.basename(x))\n",
    "\n",
    "# Map the ground truth text using the unique video annotations\n",
    "df_results['GT'] = df_results['movie_name'].map(unique_video_annotations.set_index('movie_name')['text'])\n",
    "\n",
    "# Save merged file\n",
    "df_results.to_csv(merged_output_path, index=False)\n",
    "print(f\"Updated dataset with GT column saved to {merged_output_path}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Load evaluation models: BERT and Sentence-BERT\n",
    "# -------------------------------\n",
    "print(\"Loading BERT and Sentence-BERT models ...\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# -------------------------------\n",
    "# Helper functions for embeddings and similarity\n",
    "# -------------------------------\n",
    "def get_bert_embedding(text):\n",
    "    \"\"\"Returns an embedding (numpy array) for a single text using BERT.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state  # (batch, seq_length, hidden_size)\n",
    "    attention_mask = inputs['attention_mask'].unsqueeze(-1)  # (batch, seq_length, 1)\n",
    "    masked_embeddings = token_embeddings * attention_mask\n",
    "    sum_embeddings = masked_embeddings.sum(dim=1)  # (batch, hidden_size)\n",
    "    valid_token_count = attention_mask.sum(dim=1)\n",
    "    average_embedding = sum_embeddings / valid_token_count\n",
    "    return average_embedding.squeeze(0).numpy()\n",
    "\n",
    "def get_sbert_embedding(texts):\n",
    "    \"\"\"Returns embeddings as a tensor for a list of texts using Sentence-BERT.\"\"\"\n",
    "    return sentence_model.encode(texts, convert_to_tensor=True)\n",
    "\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    \"\"\"Returns the cosine similarity between two 2D arrays (shape [1, d]).\"\"\"\n",
    "    return cosine_similarity(embedding1, embedding2)[0][0]\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluation per group\n",
    "# -------------------------------\n",
    "def evaluate_group_bert(group):\n",
    "    \"\"\"\n",
    "    Computes the average cosine similarity for a group of rows using BERT.\n",
    "    Each row's predicted text and ground truth (GT) text are embedded individually.\n",
    "    \"\"\"\n",
    "    sims = []\n",
    "    for _, row in group.iterrows():\n",
    "        test_text = str(row['test_deepfake_analysis'])\n",
    "        gt_text = str(row['GT'])\n",
    "        if test_text and gt_text:\n",
    "            emb_test = get_bert_embedding(test_text).reshape(1, -1)\n",
    "            emb_gt = get_bert_embedding(gt_text).reshape(1, -1)\n",
    "            sim = calculate_cosine_similarity(emb_test, emb_gt)\n",
    "            sims.append(sim)\n",
    "    return sum(sims) / len(sims) if sims else 0.0\n",
    "\n",
    "def evaluate_group_sbert(group):\n",
    "    \"\"\"\n",
    "    Computes the average cosine similarity for a group of rows using Sentence-BERT.\n",
    "    It obtains embeddings for all test texts and GT texts in batch.\n",
    "    \"\"\"\n",
    "    test_texts = group['test_deepfake_analysis'].astype(str).tolist()\n",
    "    gt_texts = group['GT'].astype(str).tolist()\n",
    "    if not test_texts or not gt_texts or len(test_texts) != len(gt_texts):\n",
    "        return 0.0\n",
    "    test_emb = get_sbert_embedding(test_texts)\n",
    "    gt_emb = get_sbert_embedding(gt_texts)\n",
    "    sims = []\n",
    "    for i in range(len(test_texts)):\n",
    "        sim = calculate_cosine_similarity(\n",
    "            test_emb[i].cpu().unsqueeze(0).numpy(),\n",
    "            gt_emb[i].cpu().unsqueeze(0).numpy()\n",
    "        )\n",
    "        sims.append(sim)\n",
    "    return sum(sims) / len(sims) if sims else 0.0\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluation loop over groups\n",
    "# -------------------------------\n",
    "\n",
    "group_columns = ['rn_model', 'extraction_layer', 'top_k', 'movie_name']\n",
    "grouped = df_results.groupby(group_columns)\n",
    "\n",
    "evaluation_records = []\n",
    "for group_name, group in grouped:\n",
    "    avg_sim_bert = evaluate_group_bert(group)\n",
    "    avg_sim_sbert = evaluate_group_sbert(group)\n",
    "    evaluation_records.append({\n",
    "        'rn_model': group_name[0],\n",
    "        'extraction_layer': group_name[1],\n",
    "        'top_k': group_name[2],\n",
    "        'movie_name': group_name[3],\n",
    "        'avg_cosine_similarity_bert': avg_sim_bert,\n",
    "        'avg_cosine_similarity_sbert': avg_sim_sbert,\n",
    "        'num_samples': len(group)\n",
    "    })\n",
    "\n",
    "eval_df = pd.DataFrame(evaluation_records)\n",
    "\n",
    "overall_avg_bert = eval_df['avg_cosine_similarity_bert'].mean()\n",
    "overall_avg_sbert = eval_df['avg_cosine_similarity_sbert'].mean()\n",
    "\n",
    "print(f'Overall Average Cosine Similarity (BERT): {overall_avg_bert}')\n",
    "print(f'Overall Average Cosine Similarity (Sentence-BERT): {overall_avg_sbert}')\n",
    "\n",
    "# Save the evaluation results\n",
    "eval_df.to_csv(evaluation_output_path, index=False)\n",
    "print(f\"Evaluation results saved to {evaluation_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here on is old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset with GT column saved to C:\\transf\\XAI_DEEPFAKE\\LLaVA\\llava\\similarity_results_clip_first_resnet101_merged.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dataset_path = r'C:\\transf\\XAI_DEEPFAKE\\dataset.csv'\n",
    "similarity_results_path = r'C:\\transf\\XAI_DEEPFAKE\\LLaVA\\llava\\similarity_results_clip_first_resnet101.csv'\n",
    "\n",
    "video_annotations = pd.read_csv(dataset_path)\n",
    "similarity_results = pd.read_csv(similarity_results_path)\n",
    "\n",
    "video_annotations = video_annotations[['movie_name', 'text']]\n",
    "\n",
    "# Remove duplicates to ensure unique movie_name for mapping\n",
    "unique_video_annotations = video_annotations.drop_duplicates(subset='movie_name')\n",
    "\n",
    "# Extract movie names from validation_video paths in the second dataset\n",
    "similarity_results['movie_name'] = similarity_results['validation_video'].apply(lambda x: os.path.basename(x))\n",
    "\n",
    "# Map the GT column using the unique video annotations\n",
    "similarity_results['GT'] = similarity_results['movie_name'].map(\n",
    "    unique_video_annotations.set_index('movie_name')['text']\n",
    ")\n",
    "\n",
    "output_path = r'C:\\transf\\XAI_DEEPFAKE\\LLaVA\\llava\\similarity_results_clip_first_resnet101_merged.csv'\n",
    "similarity_results.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Updated dataset with GT column saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cosine Similarity (BERT): 0.6104885384598824\n",
      "Average Cosine Similarity (Sentence BERT): 0.3906248190890642\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "file_path = r'C:\\transf\\XAI_DEEPFAKE\\LLaVA\\llava\\similarity_results_clip_first_resnet101_merged.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Group data by validation video ID\n",
    "video_groups = df.groupby('validation_video')\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained Sentence BERT model\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to get BERT embeddings\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    # Use the average of token embeddings (excluding padding tokens) for the embedding\n",
    "    token_embeddings = outputs.last_hidden_state  # Shape: (batch_size, seq_length, hidden_size)\n",
    "    attention_mask = inputs['attention_mask'].unsqueeze(-1)  # Shape: (batch_size, seq_length, 1)\n",
    "    masked_embeddings = token_embeddings * attention_mask\n",
    "    sum_embeddings = masked_embeddings.sum(dim=1)  # Shape: (batch_size, hidden_size)\n",
    "    valid_token_count = attention_mask.sum(dim=1)  # Shape: (batch_size, 1)\n",
    "    average_embedding = sum_embeddings / valid_token_count  # Shape: (batch_size, hidden_size)\n",
    "    return average_embedding.squeeze(0).numpy()\n",
    "\n",
    "# Function to get Sentence BERT embeddings\n",
    "def get_sbert_embedding(texts):\n",
    "    return sentence_model.encode(texts, convert_to_tensor=True)\n",
    "\n",
    "# Function to calculate cosine similarity between embeddings\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    return cosine_similarity(embedding1, embedding2)[0][0]\n",
    "\n",
    "# Function to calculate average cosine similarity per video\n",
    "def calculate_average_cosine_similarity(group, embed_func):\n",
    "    test_texts = group['test_deepfake_analysis'].astype(str).tolist()\n",
    "    gt_texts = group['GT'].astype(str).tolist()\n",
    "    \n",
    "    if not test_texts or not gt_texts:\n",
    "        return 0.0\n",
    "    \n",
    "    test_embeddings = [embed_func(text) for text in test_texts]\n",
    "    gt_embeddings = [embed_func(text) for text in gt_texts]\n",
    "    \n",
    "    # Calculate cosine similarities for each pair of test and ground truth text\n",
    "    cosine_similarities = [\n",
    "        calculate_cosine_similarity(test_emb.reshape(1, -1), gt_emb.reshape(1, -1))\n",
    "        for test_emb, gt_emb in zip(test_embeddings, gt_embeddings)\n",
    "    ]\n",
    "    \n",
    "    # Return the average cosine similarity for the video group\n",
    "    return sum(cosine_similarities) / len(cosine_similarities) if cosine_similarities else 0.0\n",
    "\n",
    "# Calculate average cosine similarity per video using BERT\n",
    "bert_similarities = [\n",
    "    calculate_average_cosine_similarity(group, get_bert_embedding)\n",
    "    for _, group in video_groups\n",
    "]\n",
    "average_cosine_similarity_bert = sum(bert_similarities) / len(bert_similarities) if bert_similarities else 0.0\n",
    "print(f'Average Cosine Similarity (BERT): {average_cosine_similarity_bert}')\n",
    "\n",
    "# Calculate average cosine similarity per video using Sentence BERT\n",
    "sbert_similarities = []\n",
    "for _, group in video_groups:\n",
    "    test_texts = group['test_deepfake_analysis'].astype(str).tolist()\n",
    "    gt_texts = group['GT'].astype(str).tolist()\n",
    "    \n",
    "    if not test_texts or not gt_texts:\n",
    "        sbert_similarities.append(0.0)\n",
    "        continue\n",
    "    \n",
    "    # Get embeddings for both columns using Sentence BERT\n",
    "    test_embeddings_sbert = get_sbert_embedding(test_texts)\n",
    "    gt_embeddings_sbert = get_sbert_embedding(gt_texts)\n",
    "    \n",
    "    # Calculate cosine similarities for each pair of test and ground truth text\n",
    "    cosine_similarities_sbert = [\n",
    "        calculate_cosine_similarity(test_emb.cpu().unsqueeze(0).numpy(), gt_emb.cpu().unsqueeze(0).numpy())\n",
    "        for test_emb, gt_emb in zip(test_embeddings_sbert, gt_embeddings_sbert)\n",
    "    ]\n",
    "    \n",
    "    sbert_similarities.append(sum(cosine_similarities_sbert) / len(cosine_similarities_sbert) if cosine_similarities_sbert else 0.0)\n",
    "\n",
    "average_cosine_similarity_sbert = sum(sbert_similarities) / len(sbert_similarities) if sbert_similarities else 0.0\n",
    "print(f'Average Cosine Similarity (Sentence BERT): {average_cosine_similarity_sbert}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vlad's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_0\\nwvloufjty.mp4, Average Cosine Similarity (Sentence BERT): 0.5041042238134934\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_0\\ybefzibreb.mp4, Average Cosine Similarity (Sentence BERT): 0.4646438658237457\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_2\\saokspyemj.mp4, Average Cosine Similarity (Sentence BERT): 0.2826147973537445\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_2\\uqvxjfpwdo.mp4, Average Cosine Similarity (Sentence BERT): 0.5507005055745443\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_2\\yirhsptlko.mp4, Average Cosine Similarity (Sentence BERT): 0.2960479259490967\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\aafuphyhpt.mp4, Average Cosine Similarity (Sentence BERT): 0.5278265216358492\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\alzajhomle.mp4, Average Cosine Similarity (Sentence BERT): 0.3787749111652374\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\aofjdfbvsf.mp4, Average Cosine Similarity (Sentence BERT): 0.5984037531579122\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\bfawveelwz.mp4, Average Cosine Similarity (Sentence BERT): 0.37493823664660203\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\bvylomlyys.mp4, Average Cosine Similarity (Sentence BERT): 0.41728597714729815\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\ciepqxjamz.mp4, Average Cosine Similarity (Sentence BERT): 0.5044117349035591\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\ghwlogkoic.mp4, Average Cosine Similarity (Sentence BERT): 0.43631320115885863\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\ixcrtusrfi.mp4, Average Cosine Similarity (Sentence BERT): 0.4922509832985395\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\kigbymagcu.mp4, Average Cosine Similarity (Sentence BERT): 0.35053039365908045\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\kisvmxjmeb.mp4, Average Cosine Similarity (Sentence BERT): 0.5411005584937192\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\lhurhgpffk.mp4, Average Cosine Similarity (Sentence BERT): 0.37985822013793474\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\luhndqsljl.mp4, Average Cosine Similarity (Sentence BERT): 0.4191003143787384\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\mjlqcikpbb.mp4, Average Cosine Similarity (Sentence BERT): 0.4145495495806535\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\avtdwylihb.mp4, Average Cosine Similarity (Sentence BERT): 0.3826547941109963\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\cbxtulzkxr.mp4, Average Cosine Similarity (Sentence BERT): 0.4237179642548052\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\cfmiliboth.mp4, Average Cosine Similarity (Sentence BERT): 0.5242081267648726\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\ctzvhowbhr.mp4, Average Cosine Similarity (Sentence BERT): 0.5713199661869012\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\czlanpxaoq.mp4, Average Cosine Similarity (Sentence BERT): 0.4676913175148282\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\flnhfqfhsk.mp4, Average Cosine Similarity (Sentence BERT): 0.41691471841133537\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\gicqpeyqxs.mp4, Average Cosine Similarity (Sentence BERT): 0.5927210146566171\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\hjblygobtf.mp4, Average Cosine Similarity (Sentence BERT): 0.4506596409864387\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\hmqcnrnldb.mp4, Average Cosine Similarity (Sentence BERT): 0.4901460374216583\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\hoaweiathp.mp4, Average Cosine Similarity (Sentence BERT): 0.45710803597104405\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\howruupkxw.mp4, Average Cosine Similarity (Sentence BERT): 0.4255038839693051\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\iuttprjxhf.mp4, Average Cosine Similarity (Sentence BERT): 0.4214198698663465\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\jruqdkdnnz.mp4, Average Cosine Similarity (Sentence BERT): 0.49644517396082327\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\kxqpyldfzj.mp4, Average Cosine Similarity (Sentence BERT): 0.2811187303191797\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\ltdwtgrads.mp4, Average Cosine Similarity (Sentence BERT): 0.41188758611679077\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\mpkmkclffv.mp4, Average Cosine Similarity (Sentence BERT): 0.36438600714755265\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\mvathrqhbe.mp4, Average Cosine Similarity (Sentence BERT): 0.49439223837341273\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\004_M101.mp4, Average Cosine Similarity (Sentence BERT): 0.3976987631598708\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\008_W101.mp4, Average Cosine Similarity (Sentence BERT): 0.3456122502991278\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\025_W007.mp4, Average Cosine Similarity (Sentence BERT): 0.36239667310476575\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\033_M114.mp4, Average Cosine Similarity (Sentence BERT): 0.38755480826229505\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\035_M114.mp4, Average Cosine Similarity (Sentence BERT): 0.32751569805211533\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\036_M114.mp4, Average Cosine Similarity (Sentence BERT): 0.3295830252870295\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\039_M114.mp4, Average Cosine Similarity (Sentence BERT): 0.21686904605063448\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\041_M115.mp4, Average Cosine Similarity (Sentence BERT): 0.31017789972990223\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\065_W005.mp4, Average Cosine Similarity (Sentence BERT): 0.12629330011502984\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\081_M120.mp4, Average Cosine Similarity (Sentence BERT): 0.421368751362714\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\087_M120.mp4, Average Cosine Similarity (Sentence BERT): 0.40435205301761784\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\089_W016.mp4, Average Cosine Similarity (Sentence BERT): 0.5798224067801235\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\091_W017.mp4, Average Cosine Similarity (Sentence BERT): 0.3796046092330409\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\095_W017.mp4, Average Cosine Similarity (Sentence BERT): 0.45296448419742835\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\118_W132.mp4, Average Cosine Similarity (Sentence BERT): 0.30164315106877776\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\160_M005.mp4, Average Cosine Similarity (Sentence BERT): 0.3879660951687854\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\165_W028.mp4, Average Cosine Similarity (Sentence BERT): 0.37076566896295104\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\166_W028.mp4, Average Cosine Similarity (Sentence BERT): 0.4793942213058472\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\175_M133.mp4, Average Cosine Similarity (Sentence BERT): 0.5084972695785973\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\191_W032.mp4, Average Cosine Similarity (Sentence BERT): 0.4612244952333809\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\228_M011.mp4, Average Cosine Similarity (Sentence BERT): 0.43689877110316605\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\256_W042.mp4, Average Cosine Similarity (Sentence BERT): 0.3357643681327378\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\259_M014.mp4, Average Cosine Similarity (Sentence BERT): 0.06831519478777741\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\265_W111.mp4, Average Cosine Similarity (Sentence BERT): 0.36376168179744184\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\281_W116.mp4, Average Cosine Similarity (Sentence BERT): 0.3387232788058472\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\283_M134.mp4, Average Cosine Similarity (Sentence BERT): 0.3035520718110951\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\287_W125.mp4, Average Cosine Similarity (Sentence BERT): 0.38229363984824144\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\299_M105.mp4, Average Cosine Similarity (Sentence BERT): 0.2767621628494002\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\304_M019.mp4, Average Cosine Similarity (Sentence BERT): 0.054829928661869275\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\306_M019.mp4, Average Cosine Similarity (Sentence BERT): 0.30057887650313697\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\307_M019.mp4, Average Cosine Similarity (Sentence BERT): 0.31516000166839436\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\309_W101.mp4, Average Cosine Similarity (Sentence BERT): 0.4190269134962399\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\311_M135.mp4, Average Cosine Similarity (Sentence BERT): 0.4046003698724389\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\312_W101.mp4, Average Cosine Similarity (Sentence BERT): 0.2635487242331146\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\326_M021.mp4, Average Cosine Similarity (Sentence BERT): 0.47240243949769567\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\328_W008.mp4, Average Cosine Similarity (Sentence BERT): 0.34919696331286126\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\335_M022.mp4, Average Cosine Similarity (Sentence BERT): 0.42369878617246903\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\348_W131.mp4, Average Cosine Similarity (Sentence BERT): 0.5012034352652095\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\363_M025.mp4, Average Cosine Similarity (Sentence BERT): 0.287288861356739\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\368_W005.mp4, Average Cosine Similarity (Sentence BERT): 0.5350099638954318\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\378_W014.mp4, Average Cosine Similarity (Sentence BERT): 0.36261588223686303\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\384_M027.mp4, Average Cosine Similarity (Sentence BERT): 0.38278285126161277\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\395_M028.mp4, Average Cosine Similarity (Sentence BERT): 0.5133151976454535\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\398_W017.mp4, Average Cosine Similarity (Sentence BERT): 0.46743187983193746\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\407_M029.mp4, Average Cosine Similarity (Sentence BERT): 0.12706459387641744\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\409_M030.mp4, Average Cosine Similarity (Sentence BERT): 0.3068052801614534\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\410_W019.mp4, Average Cosine Similarity (Sentence BERT): 0.5021697147263461\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\430_W022.mp4, Average Cosine Similarity (Sentence BERT): 0.5714923547300198\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\432_M136.mp4, Average Cosine Similarity (Sentence BERT): 0.18939644144725715\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\443_M137.mp4, Average Cosine Similarity (Sentence BERT): 0.26967585883150375\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\451_M138.mp4, Average Cosine Similarity (Sentence BERT): 0.22011128238093836\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\457_W025.mp4, Average Cosine Similarity (Sentence BERT): 0.3654488659322672\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\465_W026.mp4, Average Cosine Similarity (Sentence BERT): 0.5504404051835676\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\470_M139.mp4, Average Cosine Similarity (Sentence BERT): 0.3071623379492691\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\486_W031.mp4, Average Cosine Similarity (Sentence BERT): 0.4628208655515153\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\489_M038.mp4, Average Cosine Similarity (Sentence BERT): 0.37052616128824956\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\492_M038.mp4, Average Cosine Similarity (Sentence BERT): 0.299857661679951\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\569_M115.mp4, Average Cosine Similarity (Sentence BERT): 0.4674228956367182\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\716_W019.mp4, Average Cosine Similarity (Sentence BERT): 0.3803072970609813\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\779_M013.mp4, Average Cosine Similarity (Sentence BERT): 0.3963413238504996\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\848_M021.mp4, Average Cosine Similarity (Sentence BERT): 0.38199704671060014\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\862_W039.mp4, Average Cosine Similarity (Sentence BERT): 0.28501566412486606\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\874_M025.mp4, Average Cosine Similarity (Sentence BERT): 0.23449359847227594\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\903_M029.mp4, Average Cosine Similarity (Sentence BERT): 0.3166067898273468\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\940_W100.mp4, Average Cosine Similarity (Sentence BERT): 0.3415063962399437\n",
      "Overall Average Cosine Similarity (Sentence BERT): 0.39062480529590715\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Load the CSV data\n",
    "file_path = r'C:\\transf\\XAI_DEEPFAKE\\LLaVA\\llava\\similarity_results_clip_first_resnet101_merged.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Group data by validation video ID\n",
    "video_groups = df.groupby('validation_video')\n",
    "\n",
    "# Load pre-trained Sentence BERT model\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to get Sentence BERT embeddings\n",
    "def get_sbert_embedding(texts):\n",
    "    return [sentence_model.encode(text, show_progress_bar=False, convert_to_tensor=False) for text in texts]\n",
    "\n",
    "# Function to calculate cosine similarity between embeddings\n",
    "def cosine_similarity(y_true, y_pred):\n",
    "    return 1 - distance.cosine(y_true, y_pred)\n",
    "\n",
    "# Calculate cosine similarity per frame and average per video using Sentence BERT\n",
    "sbert_similarities = []\n",
    "for video_id, group in video_groups:\n",
    "    test_texts = group['test_deepfake_analysis'].astype(str).tolist()\n",
    "    gt_texts = group['GT'].astype(str).tolist()\n",
    "    \n",
    "    # Handle empty or missing values\n",
    "    if not test_texts or not gt_texts:\n",
    "        sbert_similarities.append((video_id, 0.0))\n",
    "        continue\n",
    "    \n",
    "    # Get embeddings for both columns using Sentence BERT\n",
    "    test_embeddings_sbert = get_sbert_embedding(test_texts)\n",
    "    gt_embeddings_sbert = get_sbert_embedding(gt_texts)\n",
    "    \n",
    "    # Calculate cosine similarities for each frame\n",
    "    frame_similarities = [\n",
    "        cosine_similarity(test_emb, gt_emb)\n",
    "        for test_emb, gt_emb in zip(test_embeddings_sbert, gt_embeddings_sbert)\n",
    "    ]\n",
    "    \n",
    "    # Calculate average cosine similarity for the video group\n",
    "    avg_cosine_similarity = sum(frame_similarities) / len(frame_similarities) if frame_similarities else 0.0\n",
    "    sbert_similarities.append((video_id, avg_cosine_similarity))\n",
    "\n",
    "# Print average cosine similarity per video\n",
    "for video_id, similarity in sbert_similarities:\n",
    "    print(f'Video ID: {video_id}, Average Cosine Similarity (Sentence BERT): {similarity}')\n",
    "\n",
    "# Calculate overall average cosine similarity\n",
    "average_cosine_similarity_sbert = sum(similarity for _, similarity in sbert_similarities) / len(sbert_similarities) if sbert_similarities else 0.0\n",
    "print(f'Overall Average Cosine Similarity (Sentence BERT): {average_cosine_similarity_sbert}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_0\\nwvloufjty.mp4, Highest Cosine Similarity (Sentence BERT): 0.555360727863229\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_0\\ybefzibreb.mp4, Highest Cosine Similarity (Sentence BERT): 0.4646438658237457\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_2\\saokspyemj.mp4, Highest Cosine Similarity (Sentence BERT): 0.2826147973537445\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_2\\uqvxjfpwdo.mp4, Highest Cosine Similarity (Sentence BERT): 0.6050755977630615\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_2\\yirhsptlko.mp4, Highest Cosine Similarity (Sentence BERT): 0.34830328822135925\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\aafuphyhpt.mp4, Highest Cosine Similarity (Sentence BERT): 0.6250597238540649\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\alzajhomle.mp4, Highest Cosine Similarity (Sentence BERT): 0.39397740364074707\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\aofjdfbvsf.mp4, Highest Cosine Similarity (Sentence BERT): 0.6437891721725464\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\bfawveelwz.mp4, Highest Cosine Similarity (Sentence BERT): 0.4409734904766083\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\bvylomlyys.mp4, Highest Cosine Similarity (Sentence BERT): 0.6010079383850098\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\ciepqxjamz.mp4, Highest Cosine Similarity (Sentence BERT): 0.5830518950850911\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\ghwlogkoic.mp4, Highest Cosine Similarity (Sentence BERT): 0.47643525828228195\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\ixcrtusrfi.mp4, Highest Cosine Similarity (Sentence BERT): 0.5745936885718304\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\kigbymagcu.mp4, Highest Cosine Similarity (Sentence BERT): 0.3796886205673218\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\kisvmxjmeb.mp4, Highest Cosine Similarity (Sentence BERT): 0.58122755829178\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\lhurhgpffk.mp4, Highest Cosine Similarity (Sentence BERT): 0.4342238436407998\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\luhndqsljl.mp4, Highest Cosine Similarity (Sentence BERT): 0.5287696123123169\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_48\\mjlqcikpbb.mp4, Highest Cosine Similarity (Sentence BERT): 0.48713320570390284\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\avtdwylihb.mp4, Highest Cosine Similarity (Sentence BERT): 0.4431748722091402\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\cbxtulzkxr.mp4, Highest Cosine Similarity (Sentence BERT): 0.4852952352342159\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\cfmiliboth.mp4, Highest Cosine Similarity (Sentence BERT): 0.5772629552263905\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\ctzvhowbhr.mp4, Highest Cosine Similarity (Sentence BERT): 0.6071823239326477\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\czlanpxaoq.mp4, Highest Cosine Similarity (Sentence BERT): 0.5331817865371704\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\flnhfqfhsk.mp4, Highest Cosine Similarity (Sentence BERT): 0.45545270773486624\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\gicqpeyqxs.mp4, Highest Cosine Similarity (Sentence BERT): 0.7112369113423294\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\hjblygobtf.mp4, Highest Cosine Similarity (Sentence BERT): 0.5262861722367581\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\hmqcnrnldb.mp4, Highest Cosine Similarity (Sentence BERT): 0.5672693759741844\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\hoaweiathp.mp4, Highest Cosine Similarity (Sentence BERT): 0.534400375747704\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\howruupkxw.mp4, Highest Cosine Similarity (Sentence BERT): 0.5086562330331672\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\iuttprjxhf.mp4, Highest Cosine Similarity (Sentence BERT): 0.4496812552403664\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\jruqdkdnnz.mp4, Highest Cosine Similarity (Sentence BERT): 0.590972553607534\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\kxqpyldfzj.mp4, Highest Cosine Similarity (Sentence BERT): 0.30842639157614815\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\ltdwtgrads.mp4, Highest Cosine Similarity (Sentence BERT): 0.452384889125824\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\mpkmkclffv.mp4, Highest Cosine Similarity (Sentence BERT): 0.46163861110555815\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\dfdc_train_part_49\\mvathrqhbe.mp4, Highest Cosine Similarity (Sentence BERT): 0.5219829678535461\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\004_M101.mp4, Highest Cosine Similarity (Sentence BERT): 0.4572840307524231\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\008_W101.mp4, Highest Cosine Similarity (Sentence BERT): 0.43349206051183187\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\025_W007.mp4, Highest Cosine Similarity (Sentence BERT): 0.36860860492612746\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\033_M114.mp4, Highest Cosine Similarity (Sentence BERT): 0.47673530807302344\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\035_M114.mp4, Highest Cosine Similarity (Sentence BERT): 0.44537967769028763\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\036_M114.mp4, Highest Cosine Similarity (Sentence BERT): 0.34513548939612626\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\039_M114.mp4, Highest Cosine Similarity (Sentence BERT): 0.2887990004540091\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\041_M115.mp4, Highest Cosine Similarity (Sentence BERT): 0.3381320934931069\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\065_W005.mp4, Highest Cosine Similarity (Sentence BERT): 0.157122498326153\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\081_M120.mp4, Highest Cosine Similarity (Sentence BERT): 0.44749481111827083\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\087_M120.mp4, Highest Cosine Similarity (Sentence BERT): 0.5221760739841548\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\089_W016.mp4, Highest Cosine Similarity (Sentence BERT): 0.626708708601672\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\091_W017.mp4, Highest Cosine Similarity (Sentence BERT): 0.4479508399963379\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\095_W017.mp4, Highest Cosine Similarity (Sentence BERT): 0.5456450581550598\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\118_W132.mp4, Highest Cosine Similarity (Sentence BERT): 0.5516980886459351\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\160_M005.mp4, Highest Cosine Similarity (Sentence BERT): 0.4713189742362196\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\165_W028.mp4, Highest Cosine Similarity (Sentence BERT): 0.46841448921984896\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\166_W028.mp4, Highest Cosine Similarity (Sentence BERT): 0.5277272462844849\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\175_M133.mp4, Highest Cosine Similarity (Sentence BERT): 0.6155584087635046\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\191_W032.mp4, Highest Cosine Similarity (Sentence BERT): 0.5100014513731876\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\228_M011.mp4, Highest Cosine Similarity (Sentence BERT): 0.5286514197172465\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\256_W042.mp4, Highest Cosine Similarity (Sentence BERT): 0.42787032889546994\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\259_M014.mp4, Highest Cosine Similarity (Sentence BERT): 0.14516350626945496\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\265_W111.mp4, Highest Cosine Similarity (Sentence BERT): 0.4317222237586975\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\281_W116.mp4, Highest Cosine Similarity (Sentence BERT): 0.37326306104660034\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\283_M134.mp4, Highest Cosine Similarity (Sentence BERT): 0.34943699836730957\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\287_W125.mp4, Highest Cosine Similarity (Sentence BERT): 0.4657580554485321\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\299_M105.mp4, Highest Cosine Similarity (Sentence BERT): 0.35247106239372183\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\304_M019.mp4, Highest Cosine Similarity (Sentence BERT): 0.07334301531401444\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\306_M019.mp4, Highest Cosine Similarity (Sentence BERT): 0.32752559617009247\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\307_M019.mp4, Highest Cosine Similarity (Sentence BERT): 0.36844799706649867\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\309_W101.mp4, Highest Cosine Similarity (Sentence BERT): 0.4924894869327545\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\311_M135.mp4, Highest Cosine Similarity (Sentence BERT): 0.5695621114708261\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\312_W101.mp4, Highest Cosine Similarity (Sentence BERT): 0.33910944098886553\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\326_M021.mp4, Highest Cosine Similarity (Sentence BERT): 0.549405390095072\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\328_W008.mp4, Highest Cosine Similarity (Sentence BERT): 0.4848405122756958\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\335_M022.mp4, Highest Cosine Similarity (Sentence BERT): 0.5143808433044469\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\348_W131.mp4, Highest Cosine Similarity (Sentence BERT): 0.5869444608688354\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\363_M025.mp4, Highest Cosine Similarity (Sentence BERT): 0.33189941441713033\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\368_W005.mp4, Highest Cosine Similarity (Sentence BERT): 0.5681449940247835\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\378_W014.mp4, Highest Cosine Similarity (Sentence BERT): 0.4000837445309017\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\384_M027.mp4, Highest Cosine Similarity (Sentence BERT): 0.4321556172185431\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\395_M028.mp4, Highest Cosine Similarity (Sentence BERT): 0.589131169539499\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\398_W017.mp4, Highest Cosine Similarity (Sentence BERT): 0.4908095598220825\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\407_M029.mp4, Highest Cosine Similarity (Sentence BERT): 0.1637288234395493\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\409_M030.mp4, Highest Cosine Similarity (Sentence BERT): 0.4389667249341779\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\410_W019.mp4, Highest Cosine Similarity (Sentence BERT): 0.6142032742500305\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\430_W022.mp4, Highest Cosine Similarity (Sentence BERT): 0.6700229048728943\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\432_M136.mp4, Highest Cosine Similarity (Sentence BERT): 0.28641832728440564\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\443_M137.mp4, Highest Cosine Similarity (Sentence BERT): 0.3454985629467886\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\451_M138.mp4, Highest Cosine Similarity (Sentence BERT): 0.3806199360263316\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\457_W025.mp4, Highest Cosine Similarity (Sentence BERT): 0.5589500665664673\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\465_W026.mp4, Highest Cosine Similarity (Sentence BERT): 0.6253303475776422\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\470_M139.mp4, Highest Cosine Similarity (Sentence BERT): 0.38581591163968576\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\486_W031.mp4, Highest Cosine Similarity (Sentence BERT): 0.5261126317415428\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\489_M038.mp4, Highest Cosine Similarity (Sentence BERT): 0.38133359662690247\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\492_M038.mp4, Highest Cosine Similarity (Sentence BERT): 0.38928039041997176\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\569_M115.mp4, Highest Cosine Similarity (Sentence BERT): 0.513239398993236\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\716_W019.mp4, Highest Cosine Similarity (Sentence BERT): 0.4129283849277613\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\779_M013.mp4, Highest Cosine Similarity (Sentence BERT): 0.4579805458795707\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\848_M021.mp4, Highest Cosine Similarity (Sentence BERT): 0.3920774693535257\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\862_W039.mp4, Highest Cosine Similarity (Sentence BERT): 0.2908439722908729\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\874_M025.mp4, Highest Cosine Similarity (Sentence BERT): 0.2561296224594116\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\903_M029.mp4, Highest Cosine Similarity (Sentence BERT): 0.3166067898273468\n",
      "Video ID: C:\\transf\\XAI_DEEPFAKE\\LLaVA\\end_to_end\\940_W100.mp4, Highest Cosine Similarity (Sentence BERT): 0.4238881297078173\n",
      "Overall Average of Highest Cosine Similarities (Sentence BERT): 0.4580838404143177\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Load the CSV data\n",
    "file_path = r'C:\\transf\\XAI_DEEPFAKE\\LLaVA\\llava\\similarity_results_clip_first_resnet101_merged.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Group data by validation video ID\n",
    "video_groups = df.groupby('validation_video')\n",
    "\n",
    "# Load pre-trained Sentence BERT model\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to get Sentence BERT embeddings\n",
    "def get_sbert_embedding(texts):\n",
    "    return [sentence_model.encode(text, show_progress_bar=False, convert_to_tensor=False) for text in texts]\n",
    "\n",
    "# Function to calculate cosine similarity between embeddings\n",
    "def cosine_similarity(y_true, y_pred):\n",
    "    return 1 - distance.cosine(y_true, y_pred)\n",
    "\n",
    "# Calculate cosine similarity per frame and keep only the highest per video using Sentence BERT\n",
    "sbert_similarities = []\n",
    "for video_id, group in video_groups:\n",
    "    test_texts = group['test_deepfake_analysis'].astype(str).tolist()\n",
    "    gt_texts = group['GT'].astype(str).tolist()\n",
    "    \n",
    "    # Handle empty or missing values\n",
    "    if not test_texts or not gt_texts:\n",
    "        sbert_similarities.append((video_id, 0.0))\n",
    "        continue\n",
    "    \n",
    "    # Get embeddings for both columns using Sentence BERT\n",
    "    test_embeddings_sbert = get_sbert_embedding(test_texts)\n",
    "    gt_embeddings_sbert = get_sbert_embedding(gt_texts)\n",
    "    \n",
    "    # Calculate cosine similarities for each frame\n",
    "    frame_similarities = [\n",
    "        cosine_similarity(test_emb, gt_emb)\n",
    "        for test_emb, gt_emb in zip(test_embeddings_sbert, gt_embeddings_sbert)\n",
    "    ]\n",
    "    \n",
    "    # Keep only the highest cosine similarity for the video group\n",
    "    max_cosine_similarity = max(frame_similarities) if frame_similarities else 0.0\n",
    "    sbert_similarities.append((video_id, max_cosine_similarity))\n",
    "\n",
    "# Print highest cosine similarity per video\n",
    "for video_id, similarity in sbert_similarities:\n",
    "    print(f'Video ID: {video_id}, Highest Cosine Similarity (Sentence BERT): {similarity}')\n",
    "\n",
    "# Calculate overall average of highest cosine similarities\n",
    "average_cosine_similarity_sbert = sum(similarity for _, similarity in sbert_similarities) / len(sbert_similarities) if sbert_similarities else 0.0\n",
    "print(f'Overall Average of Highest Cosine Similarities (Sentence BERT): {average_cosine_similarity_sbert}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
